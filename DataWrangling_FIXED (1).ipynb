{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fd86735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries imported successfully\n",
      "Pandas version: 2.2.2\n",
      "NumPy version: 1.26.4\n",
      "\n",
      "======================================================================\n",
      "LOADING ALL DATASETS\n",
      "======================================================================\n",
      "âœ… All datasets loaded successfully\n",
      "\n",
      "Course Codes        :    7 rows Ã—  2 columns\n",
      "Meta Data           :   40 rows Ã—  3 columns\n",
      "Student Profiles    :  307 rows Ã— 15 columns\n",
      "Student Results     :  555 rows Ã—  4 columns\n",
      "Student Survey      :  543 rows Ã—  8 columns\n",
      "\n",
      "======================================================================\n",
      "DATASET 1: COURSE CODES\n",
      "======================================================================\n",
      "\n",
      "First 5 rows:\n",
      "   CODE                        COURSE NAME\n",
      "0  1101  Diploma in Data Analytics with AI\n",
      "1  1102     Diploma in Business Management\n",
      "2  2101   Certificate in Emerging Business\n",
      "3  2102   Certificate in Talent Management\n",
      "4  2013  Certificate in Data Visualization\n",
      "\n",
      "Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7 entries, 0 to 6\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   CODE         7 non-null      int64 \n",
      " 1   COURSE NAME  7 non-null      object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 244.0+ bytes\n",
      "None\n",
      "\n",
      "Missing Values:\n",
      "CODE           0\n",
      "COURSE NAME    0\n",
      "dtype: int64\n",
      "\n",
      "Unique Courses:\n",
      "['Diploma in Data Analytics with AI', 'Diploma in Business Management', 'Certificate in Emerging Business', 'Certificate in Talent Management', 'Certificate in Data Visualization', 'Specialist Diploma in eBusiness', 'Specialist Diploma in Corporate Finance']\n",
      "\n",
      "======================================================================\n",
      "DATASET 2: STUDENT PROFILES\n",
      "======================================================================\n",
      "\n",
      "First 5 rows:\n",
      "     STUDENT ID GENDER SG CITIZEN SG PR FOREIGNER  \\\n",
      "0  1101-009/001      F              NaN         Y   \n",
      "1  1101-009/002      F          Y   NaN       NaN   \n",
      "2  1101-009/003      F              NaN         Y   \n",
      "3  1101-009/004      F              NaN         Y   \n",
      "4  1101-009/005      F          Y   NaN       NaN   \n",
      "\n",
      "  COUNTRY OF OTHER NATIONALITY         DOB HIGHEST QUALIFICATION  \\\n",
      "0                     Malaysia  13/09/1981           Certificate   \n",
      "1                          NaN  26/07/1979           Certificate   \n",
      "2                        India  01/02/1990                Degree   \n",
      "3                  Netherlands  20/04/1976               Diploma   \n",
      "4                          NaN  25/11/1983               Diploma   \n",
      "\n",
      "               NAME OF QUALIFICATION AND INSTITUTION  \\\n",
      "0                                                SPM   \n",
      "1                  Certificate in Office Skills, ITE   \n",
      "2  Bachelor of Business Administration, Universit...   \n",
      "3  Office Management Diploma, NCOI Rotterdam, The...   \n",
      "4  Diploma in Business Admininstration, LCCI Leve...   \n",
      "\n",
      "  DATE ATTAINED HIGHEST QUALIFICATION                  DESIGNATION  \\\n",
      "0                          08/01/2018         Admin & HR Assistant   \n",
      "1                          08/06/2016              Admin Assistant   \n",
      "2                          08/08/2015                            -   \n",
      "3                          08/02/2018  HR Support / Office Manager   \n",
      "4                          08/06/2015    Executive, Administration   \n",
      "\n",
      "  COMMENCEMENT DATE COMPLETION DATE FULL-TIME OR PART-TIME  COURSE FUNDING  \n",
      "0        18/04/2022      17/09/2023              Part-Time      Individual  \n",
      "1        18/04/2022      17/09/2023              Part-Time  Individual-SFC  \n",
      "2        18/04/2022      17/09/2023              Part-Time      Individual  \n",
      "3        18/04/2022      17/09/2023              Part-Time      Individual  \n",
      "4        18/04/2022      17/09/2023              Part-Time       Sponsored  \n",
      "\n",
      "Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 307 entries, 0 to 306\n",
      "Data columns (total 15 columns):\n",
      " #   Column                                 Non-Null Count  Dtype \n",
      "---  ------                                 --------------  ----- \n",
      " 0   STUDENT ID                             307 non-null    object\n",
      " 1   GENDER                                 307 non-null    object\n",
      " 2   SG CITIZEN                             268 non-null    object\n",
      " 3   SG PR                                  32 non-null     object\n",
      " 4   FOREIGNER                              36 non-null     object\n",
      " 5   COUNTRY OF OTHER NATIONALITY           156 non-null    object\n",
      " 6   DOB                                    307 non-null    object\n",
      " 7   HIGHEST QUALIFICATION                  307 non-null    object\n",
      " 8   NAME OF QUALIFICATION AND INSTITUTION  307 non-null    object\n",
      " 9   DATE ATTAINED HIGHEST QUALIFICATION    307 non-null    object\n",
      " 10  DESIGNATION                            307 non-null    object\n",
      " 11  COMMENCEMENT DATE                      302 non-null    object\n",
      " 12  COMPLETION DATE                        287 non-null    object\n",
      " 13  FULL-TIME OR PART-TIME                 307 non-null    object\n",
      " 14  COURSE FUNDING                         307 non-null    object\n",
      "dtypes: object(15)\n",
      "memory usage: 36.1+ KB\n",
      "None\n",
      "\n",
      "Missing Values Summary:\n",
      "                              Missing Count  Percentage\n",
      "SG PR                                   275       89.58\n",
      "FOREIGNER                               271       88.27\n",
      "COUNTRY OF OTHER NATIONALITY            151       49.19\n",
      "SG CITIZEN                               39       12.70\n",
      "COMPLETION DATE                          20        6.51\n",
      "COMMENCEMENT DATE                         5        1.63\n",
      "\n",
      "Column Names:\n",
      " 1. STUDENT ID\n",
      " 2. GENDER\n",
      " 3. SG CITIZEN\n",
      " 4. SG PR\n",
      " 5. FOREIGNER\n",
      " 6. COUNTRY OF OTHER NATIONALITY\n",
      " 7. DOB\n",
      " 8. HIGHEST QUALIFICATION\n",
      " 9. NAME OF QUALIFICATION AND INSTITUTION\n",
      "10. DATE ATTAINED HIGHEST QUALIFICATION\n",
      "11. DESIGNATION\n",
      "12. COMMENCEMENT DATE\n",
      "13. COMPLETION DATE\n",
      "14. FULL-TIME OR PART-TIME\n",
      "15. COURSE FUNDING\n",
      "\n",
      "Sample STUDENT IDs (to understand format):\n",
      "['1101-009/001', '1101-009/002', '1101-009/003', '1101-009/004', '1101-009/005', '1101-009/006', '1101-009/007', '1101-009/008', '1101-009/009', '1101-009/010']\n",
      "\n",
      "======================================================================\n",
      "DATASET 3: STUDENT RESULTS\n",
      "======================================================================\n",
      "\n",
      "First 10 rows:\n",
      "     STUDENT ID PERIOD  GPA  ATTENDANCE\n",
      "0  1101-009/001  Sem 1  3.5         100\n",
      "1  1101-009/001  Sem 2  3.6         100\n",
      "2  1101-009/001  Sem 3  3.7          80\n",
      "3  1101-009/002  Sem 1  3.4         100\n",
      "4  1101-009/002  Sem 2  3.5          80\n",
      "5  1101-009/002  Sem 3  3.6          97\n",
      "6  1101-009/003  Sem 1  3.3         100\n",
      "7  1101-009/003  Sem 2  3.2         100\n",
      "8  1101-009/003  Sem 3  3.6          91\n",
      "9  1101-009/004  Sem 1  3.9         100\n",
      "\n",
      "Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 555 entries, 0 to 554\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   STUDENT ID  555 non-null    object \n",
      " 1   PERIOD      555 non-null    object \n",
      " 2   GPA         555 non-null    float64\n",
      " 3   ATTENDANCE  555 non-null    int64  \n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 17.5+ KB\n",
      "None\n",
      "\n",
      "Missing Values:\n",
      "STUDENT ID    0\n",
      "PERIOD        0\n",
      "GPA           0\n",
      "ATTENDANCE    0\n",
      "dtype: int64\n",
      "\n",
      "Basic Statistics:\n",
      "              GPA  ATTENDANCE\n",
      "count  555.000000  555.000000\n",
      "mean     3.107568   85.821622\n",
      "std      0.601875   12.561570\n",
      "min      1.600000   50.000000\n",
      "25%      2.700000   80.000000\n",
      "50%      3.200000   87.000000\n",
      "75%      3.600000   97.500000\n",
      "max      4.000000  100.000000\n",
      "\n",
      "Unique values per column:\n",
      "STUDENT ID     :  291 unique values\n",
      "PERIOD         :   10 unique values\n",
      "GPA            :   25 unique values\n",
      "ATTENDANCE     :   49 unique values\n",
      "\n",
      "PERIOD values:\n",
      "PERIOD\n",
      "Sem 1         223\n",
      "Sem 2         124\n",
      "Sem 3          45\n",
      "Sem 4           1\n",
      "Sem1           30\n",
      "Sem2            1\n",
      "Semester 1     56\n",
      "Semester 2     37\n",
      "Semester 3     37\n",
      "Semester 4      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "======================================================================\n",
      "DATASET 4: STUDENT SURVEY\n",
      "======================================================================\n",
      "\n",
      "First 10 rows:\n",
      "     STUDENT ID PERIOD  PRIOR KNOWLEDGE  COURSE RELEVANCE  TEACHING SUPPORT  \\\n",
      "0  1101-009/001  Sem 1                4                 3                 4   \n",
      "1  1101-009/001  Sem 2                4                 5                 5   \n",
      "2  1101-009/001  Sem 3                5                 4                 4   \n",
      "3  1101-009/002  Sem 1                2                 4                 5   \n",
      "4  1101-009/002  Sem 2                3                 5                 5   \n",
      "5  1101-009/002  Sem 3                3                 5                 5   \n",
      "6  1101-009/003  Sem 1                4                 4                 3   \n",
      "7  1101-009/003  Sem 2                4                 5                 4   \n",
      "8  1101-009/003  Sem 3                5                 4                 5   \n",
      "9  1101-009/004  Sem 1                4                 4                 3   \n",
      "\n",
      "   COMPANY SUPPORT  FAMILY SUPPORT  SELF-STUDY HRS  \n",
      "0                5               3              16  \n",
      "1                3               3              14  \n",
      "2                4               3              18  \n",
      "3                3               3              14  \n",
      "4                5               4              17  \n",
      "5                3               5              13  \n",
      "6                4               5              15  \n",
      "7                3               3              20  \n",
      "8                3               3              14  \n",
      "9                3               3              18  \n",
      "\n",
      "Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 543 entries, 0 to 542\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   STUDENT ID        543 non-null    object\n",
      " 1   PERIOD            543 non-null    object\n",
      " 2   PRIOR KNOWLEDGE   543 non-null    int64 \n",
      " 3   COURSE RELEVANCE  543 non-null    int64 \n",
      " 4   TEACHING SUPPORT  543 non-null    int64 \n",
      " 5   COMPANY SUPPORT   543 non-null    int64 \n",
      " 6   FAMILY SUPPORT    543 non-null    int64 \n",
      " 7   SELF-STUDY HRS    543 non-null    int64 \n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 34.1+ KB\n",
      "None\n",
      "\n",
      "Missing Values:\n",
      "STUDENT ID          0\n",
      "PERIOD              0\n",
      "PRIOR KNOWLEDGE     0\n",
      "COURSE RELEVANCE    0\n",
      "TEACHING SUPPORT    0\n",
      "COMPANY SUPPORT     0\n",
      "FAMILY SUPPORT      0\n",
      "SELF-STUDY HRS      0\n",
      "dtype: int64\n",
      "\n",
      "Basic Statistics:\n",
      "       PRIOR KNOWLEDGE  COURSE RELEVANCE  TEACHING SUPPORT  COMPANY SUPPORT  \\\n",
      "count       543.000000        543.000000        543.000000       543.000000   \n",
      "mean          3.686924          3.939227          3.712707         3.858195   \n",
      "std           0.862051          0.902022          1.049673         0.977686   \n",
      "min           1.000000          1.000000          1.000000         1.000000   \n",
      "25%           3.000000          3.000000          3.000000         3.000000   \n",
      "50%           4.000000          4.000000          4.000000         4.000000   \n",
      "75%           4.000000          5.000000          5.000000         5.000000   \n",
      "max           5.000000          5.000000          5.000000         5.000000   \n",
      "\n",
      "       FAMILY SUPPORT  SELF-STUDY HRS  \n",
      "count       543.00000      543.000000  \n",
      "mean          3.85267       13.384899  \n",
      "std           0.95683        4.218776  \n",
      "min           1.00000        5.000000  \n",
      "25%           3.00000       10.000000  \n",
      "50%           4.00000       13.000000  \n",
      "75%           5.00000       17.000000  \n",
      "max           5.00000       23.000000  \n",
      "\n",
      "Unique values per column:\n",
      "STUDENT ID          :  285 unique values\n",
      "PERIOD              :   10 unique values\n",
      "PRIOR KNOWLEDGE     :    5 unique values\n",
      "COURSE RELEVANCE    :    5 unique values\n",
      "TEACHING SUPPORT    :    5 unique values\n",
      "COMPANY SUPPORT     :    5 unique values\n",
      "FAMILY SUPPORT      :    5 unique values\n",
      "SELF-STUDY HRS      :   19 unique values\n",
      "\n",
      "PERIOD values:\n",
      "PERIOD\n",
      "Sem 1         238\n",
      "Sem 2         123\n",
      "Sem 3          43\n",
      "Sem 4           1\n",
      "Sem1           29\n",
      "Sem2            1\n",
      "Semester 1     36\n",
      "Semester 2     36\n",
      "Semester 3     35\n",
      "Semester 4      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "======================================================================\n",
      "PARSING STUDENT ID - EXTRACTING CLASS CODE\n",
      "======================================================================\n",
      "\n",
      "Extracting CLASS codes from STUDENT ID...\n",
      "âœ… Profiles: Extracted CLASS for 307 students\n",
      "âœ… Results: Extracted CLASS for 555 records\n",
      "âœ… Survey: Extracted CLASS for 543 records\n",
      "\n",
      "ðŸ“Š Unique CLASS codes found:\n",
      "Total unique classes: 32\n",
      "Classes: ['1101-009', '1101-010', '1101-011', '1101-012', '1102-001', '1102-002', '1102-003', '1102-004', '2101-106', '2101-107', '2101-108A', '2101-109', '2101-110', '2101-111', '2102-063', '2102-064', '2102-065A', '2102-066', '2102-067A', '2102-068A', '2102-069', '2102-070', '5112-007', '5112-008', '5112-009', '5112-010', '5112-011', '5113-005', '5113-006', '5113-007', '5113-008', '5113-009']\n",
      "\n",
      "CLASS distribution in Profiles:\n",
      "CLASS\n",
      "1101-009     11\n",
      "1101-010     12\n",
      "1101-011     10\n",
      "1101-012     11\n",
      "1102-001      8\n",
      "1102-002      7\n",
      "1102-003      7\n",
      "1102-004      8\n",
      "2101-107     10\n",
      "2101-108A     8\n",
      "2101-109      8\n",
      "2101-110      8\n",
      "2101-111      8\n",
      "2102-063     16\n",
      "2102-064     14\n",
      "2102-065A    12\n",
      "2102-066     16\n",
      "2102-067A    11\n",
      "2102-068A    10\n",
      "2102-069     11\n",
      "2102-070     11\n",
      "5112-008     14\n",
      "5112-009     11\n",
      "5112-010     10\n",
      "5112-011     10\n",
      "5113-005      7\n",
      "5113-006      7\n",
      "5113-007     17\n",
      "5113-008      7\n",
      "5113-009      7\n",
      "Name: count, dtype: int64\n",
      "\n",
      "======================================================================\n",
      "CROSS-DATASET RELATIONSHIP ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "Unique Student IDs:\n",
      "  Profiles: 295\n",
      "  Results:  291\n",
      "  Survey:   285\n",
      "\n",
      "Students in Results but NOT in Profiles: 11\n",
      "Students in Survey but NOT in Profiles:  11\n",
      "Students in Profiles but NOT in Results: 15\n",
      "Students in Profiles but NOT in Survey:  21\n",
      "\n",
      "PERIOD Analysis:\n",
      "  Results PERIOD values: ['Sem 1', 'Sem 2', 'Sem 3', 'Sem 4', 'Sem1', 'Sem2', 'Semester 1', 'Semester 2', 'Semester 3', 'Semester 4']\n",
      "  Survey PERIOD values:  ['Sem 1', 'Sem 2', 'Sem 3', 'Sem 4', 'Sem1', 'Sem2', 'Semester 1', 'Semester 2', 'Semester 3', 'Semester 4']\n",
      "\n",
      "Duplicate Analysis:\n",
      "  Profiles duplicates (STUDENT ID): 12\n",
      "  Results duplicates (STUDENT ID + PERIOD): 33\n",
      "  Survey duplicates (STUDENT ID + PERIOD): 32\n",
      "\n",
      "======================================================================\n",
      "CLEANING: COURSE CODES\n",
      "======================================================================\n",
      "Before cleaning:\n",
      "  Shape: (7, 2)\n",
      "  Nulls: 0\n",
      "\n",
      "After cleaning:\n",
      "  Shape: (7, 2)\n",
      "   CODE                              COURSE NAME\n",
      "0  1101        Diploma in Data Analytics with AI\n",
      "1  1102           Diploma in Business Management\n",
      "2  2101         Certificate in Emerging Business\n",
      "3  2102         Certificate in Talent Management\n",
      "4  2013        Certificate in Data Visualization\n",
      "5  5112          Specialist Diploma in eBusiness\n",
      "6  5113  Specialist Diploma in Corporate Finance\n",
      "\n",
      "======================================================================\n",
      "CLEANING: STUDENT PROFILES - PART 1 (Columns)\n",
      "======================================================================\n",
      "Step 1: Standardize column names\n",
      "  âœ… Standardized 16 column names\n",
      "\n",
      "Step 2: Remove whitespace from all string columns\n",
      "  âœ… Whitespace removed\n",
      "\n",
      "Step 3: Standardize and fix nationality columns\n",
      "\n",
      "ðŸ“Š BEFORE Standardization:\n",
      "SG CITIZEN unique values: ['' 'Y' nan 'Yes']\n",
      "SG PR unique values: [nan 'Y' 'Yes']\n",
      "FOREIGNER unique values: ['Y' nan]\n",
      "\n",
      "ðŸ“Š AFTER Standardization:\n",
      "SG CITIZEN unique values: ['N' 'Y']\n",
      "SG PR unique values: ['N' 'Y']\n",
      "FOREIGNER unique values: ['Y' 'N']\n",
      "\n",
      "âœ… Created NATIONALITY_STATUS column\n",
      "\n",
      "ðŸ“Š Distribution:\n",
      "NATIONALITY_STATUS\n",
      "SG Citizen    239\n",
      "Foreigner      36\n",
      "SG PR          32\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Percentages:\n",
      "  SG Citizen: 239 (77.9%)\n",
      "  Foreigner: 36 (11.7%)\n",
      "  SG PR: 32 (10.4%)\n",
      "\n",
      "âœ… No Unknown nationality cases!\n",
      "\n",
      "ðŸ” Data Quality Check:\n",
      "  âœ… No multiple flags\n",
      "  âœ… All students have flags\n",
      "\n",
      "======================================================================\n",
      "CLEANING: STUDENT PROFILES - PART 2 (Dates)\n",
      "======================================================================\n",
      "Converting date columns to datetime...\n",
      "\n",
      "Processing: DOB\n",
      "  Sample values: ['13/09/1981', '26/07/1979', '01/02/1990']\n",
      "  âœ… Converted. Nulls: 4 (1.3%)\n",
      "\n",
      "Processing: DATE ATTAINED HIGHEST QUALIFICATION\n",
      "  Sample values: ['08/01/2018', '08/06/2016', '08/08/2015']\n",
      "  âœ… Converted. Nulls: 185 (60.3%)\n",
      "\n",
      "Processing: COMMENCEMENT DATE\n",
      "  Sample values: ['18/04/2022', '18/04/2022', '18/04/2022']\n",
      "  âœ… Converted. Nulls: 23 (7.5%)\n",
      "\n",
      "Processing: COMPLETION DATE\n",
      "  Sample values: ['17/09/2023', '17/09/2023', '17/09/2023']\n",
      "  âœ… Converted. Nulls: 31 (10.1%)\n",
      "\n",
      "ðŸ”§ Converting date columns to datetime format...\n",
      "âœ… All date columns converted to datetime format\n",
      "\n",
      "Age Statistics:\n",
      "count    303.000000\n",
      "mean      41.162376\n",
      "std        9.242640\n",
      "min       15.300000\n",
      "25%       33.600000\n",
      "50%       41.000000\n",
      "75%       47.650000\n",
      "max       64.800000\n",
      "Name: AGE, dtype: float64\n",
      "\n",
      "Course Duration Statistics (before filling missing dates):\n",
      "count    269.000000\n",
      "mean     277.828996\n",
      "std      167.226722\n",
      "min       30.000000\n",
      "25%      151.000000\n",
      "50%      340.000000\n",
      "75%      346.000000\n",
      "max      700.000000\n",
      "Name: COURSE_DURATION_DAYS, dtype: float64\n",
      "\n",
      "======================================================================\n",
      "SMART DATE FILLING - USING CLASS CODE\n",
      "======================================================================\n",
      "\n",
      "ðŸ“Š BEFORE Date Filling:\n",
      "Missing COMMENCEMENT DATE: 23 rows\n",
      "Missing COMPLETION DATE: 31 rows\n",
      "\n",
      "ðŸ” Step 1: Analyzing dates by CLASS (not PERIOD)...\n",
      "\n",
      "Date Reference Table by CLASS:\n",
      "        CLASS REFERENCE_COMMENCE REFERENCE_COMPLETE\n",
      "0    1101-009         2022-04-18         2023-09-17\n",
      "1    1101-010         2022-10-19         2024-03-18\n",
      "2    1101-011         2023-04-16         2024-09-16\n",
      "3    1101-012                NaT                NaT\n",
      "4    1102-001         2022-04-18         2023-09-17\n",
      "5    1102-002         2022-10-19         2024-03-18\n",
      "6    1102-003         2023-04-16         2024-09-16\n",
      "7    1102-004         2024-04-13         2025-09-15\n",
      "8    2101-107         2022-04-24         2022-09-23\n",
      "9   2101-108A         2023-04-02         2023-06-12\n",
      "10   2101-109         2023-10-28         2024-03-13\n",
      "11   2101-110         2024-04-15         2024-09-14\n",
      "12   2101-111         2025-10-24                NaT\n",
      "13   2102-063         2022-04-18         2022-09-14\n",
      "14   2102-064         2022-10-08         2023-03-23\n",
      "15  2102-065A         2023-01-05         2023-02-04\n",
      "16   2102-066         2023-04-08         2023-09-13\n",
      "17  2102-067A         2023-10-02         2023-12-21\n",
      "18  2102-068A         2024-01-02         2024-03-08\n",
      "19   2102-069         2024-04-15         2024-09-14\n",
      "20   2102-070         2025-04-14         2025-09-12\n",
      "21   5112-008         2022-10-18         2023-09-29\n",
      "22   5112-009         2023-04-10         2024-03-17\n",
      "23   5112-010         2023-10-16         2024-09-20\n",
      "24   5112-011         2024-04-08         2025-03-18\n",
      "25   5113-005         2022-10-18         2023-09-29\n",
      "26   5113-006                NaT         2024-03-17\n",
      "27   5113-007         2023-10-16         2024-09-20\n",
      "28   5113-008         2024-04-08         2025-03-18\n",
      "29   5113-009         2025-10-14                NaT\n",
      "\n",
      "âš ï¸  WARNING: These CLASSes have NO commencement date info: ['1101-012', '5113-006']\n",
      "âš ï¸  WARNING: These CLASSes have NO completion date info: ['1101-012', '2101-111', '5113-009']\n",
      "\n",
      "ðŸ”§ Step 2: Filling missing dates based on CLASS...\n",
      "\n",
      "âœ… Filled 5 missing COMMENCEMENT DATEs\n",
      "âœ… Filled 5 missing COMPLETION DATEs\n",
      "\n",
      "ðŸ”§ Step 3: Recalculating COURSE_DURATION_DAYS...\n",
      "âœ… Calculated duration for 274 rows\n",
      "\n",
      "======================================================================\n",
      "ðŸ“Š AFTER Date Filling:\n",
      "======================================================================\n",
      "Missing COMMENCEMENT DATE: 18 rows\n",
      "Missing COMPLETION DATE: 26 rows\n",
      "Missing COURSE_DURATION_DAYS: 33 rows\n",
      "\n",
      "âš ï¸  33 rows still have missing dates:\n",
      "\n",
      "Breakdown by CLASS:\n",
      "CLASS\n",
      "1101-012    11\n",
      "2101-111     8\n",
      "5113-006     7\n",
      "5113-009     7\n",
      "Name: count, dtype: int64\n",
      "\n",
      "These CLASSes have no date information from any student.\n",
      "\n",
      "ðŸ“ˆ Course Duration Statistics:\n",
      "count    274.000000\n",
      "mean     278.963504\n",
      "std      167.316239\n",
      "min       30.000000\n",
      "25%      151.000000\n",
      "50%      340.000000\n",
      "75%      346.000000\n",
      "max      700.000000\n",
      "Name: COURSE_DURATION_DAYS, dtype: float64\n",
      "\n",
      "======================================================================\n",
      "CLEANING: STUDENT PROFILES - PART 3 (Missing Values)\n",
      "======================================================================\n",
      "\n",
      "Missing Values Summary:\n",
      "                             Column  Missing_Count  Missing_Pct\n",
      "DATE ATTAINED HIGHEST QUALIFICATION            185        60.26\n",
      "       COUNTRY OF OTHER NATIONALITY            151        49.19\n",
      "               COURSE_DURATION_DAYS             33        10.75\n",
      "                    COMPLETION DATE             26         8.47\n",
      "                  COMMENCEMENT DATE             18         5.86\n",
      "                                DOB              4         1.30\n",
      "                                AGE              4         1.30\n",
      "\n",
      "Handling missing values:\n",
      "\n",
      "  GENDER missing: 0\n",
      "\n",
      "Decision: Keep other nulls as-is, document in presentation\n",
      "\n",
      "======================================================================\n",
      "CLEANING: STUDENT RESULTS\n",
      "======================================================================\n",
      "Step 1: Standardize column names\n",
      "\n",
      "Step 2: Check and clean STUDENT ID\n",
      "\n",
      "Step 3: Clean and standardize PERIOD column\n",
      "  BEFORE: ['Sem 1' 'Sem 2' 'Sem 3' 'Sem 4' 'Semester 1' 'Semester 2' 'Semester 3'\n",
      " 'Semester 4' 'Sem1' 'Sem2']\n",
      "\n",
      "ðŸ”§ Standardizing PERIOD values in Results...\n",
      "Before: {'Sem 1': 223, 'Sem 2': 124, 'Sem 3': 45, 'Sem 4': 1, 'Sem1': 30, 'Sem2': 1, 'Semester 1': 56, 'Semester 2': 37, 'Semester 3': 37, 'Semester 4': 1}\n",
      "After: {'Sem 1': 253, 'Sem 2': 125, 'Sem 3': 45, 'Sem 4': 1, 'Semester 1': 56, 'Semester 2': 37, 'Semester 3': 37, 'Semester 4': 1}\n",
      "âœ… PERIOD values standardized in Results\n",
      "  AFTER: ['Sem 1' 'Sem 2' 'Sem 3' 'Sem 4']\n",
      "  âœ… PERIOD standardized\n",
      "\n",
      "Step 4: Validate GPA values\n",
      "  GPA range: 1.60 to 4.00\n",
      "  âœ… All GPA values are valid\n",
      "  Null GPAs: 0\n",
      "\n",
      "Step 5: Validate ATTENDANCE values\n",
      "  ATTENDANCE range: 50 to 100\n",
      "  Null ATTENDANCE: 0\n",
      "  âœ… All ATTENDANCE values are valid\n",
      "\n",
      "ðŸ” Re-checking duplicates after PERIOD standardization...\n",
      "  âš ï¸  Found 33 new duplicates after standardization\n",
      "  âœ… Removed duplicates\n",
      "\n",
      "Step 6: Check for duplicate records\n",
      "  Duplicates (STUDENT ID + PERIOD): 0\n",
      "\n",
      "Final shape: (522, 5)\n",
      "\n",
      "======================================================================\n",
      "CLEANING: STUDENT SURVEY\n",
      "======================================================================\n",
      "Step 1: Standardize column names\n",
      "\n",
      "Step 2: Clean STUDENT ID and PERIOD\n",
      "  BEFORE: ['Sem 1' 'Sem 2' 'Sem 3' 'Sem 4' 'Semester 1' 'Semester 2' 'Semester 3'\n",
      " 'Semester 4' 'Sem1' 'Sem2']\n",
      "\n",
      "ðŸ”§ Standardizing PERIOD values in Survey...\n",
      "Before: {'Sem 1': 238, 'Sem 2': 123, 'Sem 3': 43, 'Sem 4': 1, 'Sem1': 29, 'Sem2': 1, 'Semester 1': 36, 'Semester 2': 36, 'Semester 3': 35, 'Semester 4': 1}\n",
      "After: {'Sem 1': 267, 'Sem 2': 124, 'Sem 3': 43, 'Sem 4': 1, 'Semester 1': 36, 'Semester 2': 36, 'Semester 3': 35, 'Semester 4': 1}\n",
      "âœ… PERIOD values standardized in Survey\n",
      "  AFTER: ['Sem 1' 'Sem 2' 'Sem 3' 'Sem 4']\n",
      "  âœ… PERIOD standardized\n",
      "\n",
      "Step 3: Validate survey response columns\n",
      "\n",
      "  PRIOR KNOWLEDGE:\n",
      "    Range: 1 to 5\n",
      "    Nulls: 0\n",
      "    Unique: 5 values\n",
      "\n",
      "  COURSE RELEVANCE:\n",
      "    Range: 1 to 5\n",
      "    Nulls: 0\n",
      "    Unique: 5 values\n",
      "\n",
      "  TEACHING SUPPORT:\n",
      "    Range: 1 to 5\n",
      "    Nulls: 0\n",
      "    Unique: 5 values\n",
      "\n",
      "  COMPANY SUPPORT:\n",
      "    Range: 1 to 5\n",
      "    Nulls: 0\n",
      "    Unique: 5 values\n",
      "\n",
      "  FAMILY SUPPORT:\n",
      "    Range: 1 to 5\n",
      "    Nulls: 0\n",
      "    Unique: 5 values\n",
      "\n",
      "  SELF-STUDY HRS:\n",
      "    Range: 5 to 23\n",
      "    Nulls: 0\n",
      "    Unique: 19 values\n",
      "\n",
      "ðŸ” Re-checking duplicates after PERIOD standardization...\n",
      "  âš ï¸  Found 32 new duplicates after standardization\n",
      "  âœ… Removed duplicates\n",
      "\n",
      "Step 4: Check for duplicate records\n",
      "  Duplicates (STUDENT ID + PERIOD): 0\n",
      "\n",
      "Final shape: (511, 9)\n",
      "\n",
      "======================================================================\n",
      "CROSS-DATASET VALIDATION\n",
      "======================================================================\n",
      "\n",
      "Student ID Coverage:\n",
      "  Profiles: 295 students\n",
      "  Results:  291 students\n",
      "  Survey:   285 students\n",
      "\n",
      "  âš ï¸  11 students in Results without Profile:\n",
      "    ['5112-007/003', '5112-007/004', '5112-007/005', '2101-106/005', '5112-007/006', '2101-106/003', '2101-106/004', '5112-007/002', '2101-106/001', '2101-106/002']...\n",
      "\n",
      "  âš ï¸  11 students in Survey without Profile:\n",
      "    ['5112-007/003', '5112-007/004', '5112-007/005', '2101-106/005', '5112-007/006', '2101-106/003', '2101-106/004', '5112-007/002', '2101-106/001', '2101-106/002']...\n",
      "\n",
      "PERIOD Consistency:\n",
      "  Results periods: ['Sem 1', 'Sem 2', 'Sem 3', 'Sem 4']\n",
      "  Survey periods:  ['Sem 1', 'Sem 2', 'Sem 3', 'Sem 4']\n",
      "\n",
      "======================================================================\n",
      "CREATING MASTER DATASET\n",
      "======================================================================\n",
      "\n",
      "Merging strategy:\n",
      "  1. Merge Results with Survey on STUDENT ID + PERIOD\n",
      "  2. Merge with Profiles on STUDENT ID\n",
      "\n",
      "Results + Survey merge:\n",
      "  Both: 511\n",
      "  Only Results: 11\n",
      "  Only Survey: 0\n",
      "\n",
      "Master dataset created:\n",
      "  Shape: (544, 28)\n",
      "  Students: 295\n",
      "\n",
      "Master dataset columns:\n",
      "   1. STUDENT ID\n",
      "   2. GENDER\n",
      "   3. SG CITIZEN\n",
      "   4. SG PR\n",
      "   5. FOREIGNER\n",
      "   6. COUNTRY OF OTHER NATIONALITY\n",
      "   7. DOB\n",
      "   8. HIGHEST QUALIFICATION\n",
      "   9. NAME OF QUALIFICATION AND INSTITUTION\n",
      "  10. DATE ATTAINED HIGHEST QUALIFICATION\n",
      "  11. DESIGNATION\n",
      "  12. COMMENCEMENT DATE\n",
      "  13. COMPLETION DATE\n",
      "  14. FULL-TIME OR PART-TIME\n",
      "  15. COURSE FUNDING\n",
      "  16. CLASS\n",
      "  17. NATIONALITY_STATUS\n",
      "  18. AGE\n",
      "  19. COURSE_DURATION_DAYS\n",
      "  20. PERIOD\n",
      "  21. GPA\n",
      "  22. ATTENDANCE\n",
      "  23. PRIOR KNOWLEDGE\n",
      "  24. COURSE RELEVANCE\n",
      "  25. TEACHING SUPPORT\n",
      "  26. COMPANY SUPPORT\n",
      "  27. FAMILY SUPPORT\n",
      "  28. SELF-STUDY HRS\n",
      "Processing Master Dataset Deduplication...\n",
      "Done. Removed 19 duplicate rows.\n",
      "\n",
      "======================================================================\n",
      "FINAL DATA QUALITY REPORT\n",
      "======================================================================\n",
      "\n",
      "ðŸ“Š CLEANED DATASETS SUMMARY:\n",
      "\n",
      "\n",
      "ðŸ”§ Removing duplicates from Master Dataset...\n",
      "Duplicates found: 5\n",
      "Showing duplicate records:\n",
      "       STUDENT ID PERIOD  GPA  ATTENDANCE\n",
      "369  5112-008/001  Sem 1  3.2        82.0\n",
      "371  5112-008/001  Sem 1  3.2        82.0\n",
      "370  5112-008/001  Sem 2  4.0        80.0\n",
      "372  5112-008/001  Sem 2  4.0        80.0\n",
      "489  5113-007/002  Sem 1  2.0        85.0\n",
      "508  5113-007/002  Sem 1  2.0        85.0\n",
      "490  5113-007/002  Sem 2  2.4        90.0\n",
      "509  5113-007/002  Sem 2  2.4        90.0\n",
      "491  5113-007/002  Sem 3  2.8        82.0\n",
      "510  5113-007/002  Sem 3  2.8        82.0\n",
      "âœ… Removed 5 duplicate rows\n",
      "New shape: (520, 28)\n",
      "\n",
      "Course Codes:\n",
      "  Rows: 7\n",
      "  Columns: 2\n",
      "  Total Nulls: 0\n",
      "  Memory: 0.00 MB\n",
      "\n",
      "Student Profiles:\n",
      "  Rows: 307\n",
      "  Columns: 19\n",
      "  Total Nulls: 421\n",
      "  Memory: 0.24 MB\n",
      "\n",
      "Student Results:\n",
      "  Rows: 522\n",
      "  Columns: 5\n",
      "  Total Nulls: 0\n",
      "  Memory: 0.10 MB\n",
      "\n",
      "Student Survey:\n",
      "  Rows: 511\n",
      "  Columns: 9\n",
      "  Total Nulls: 0\n",
      "  Memory: 0.11 MB\n",
      "\n",
      "Master Dataset:\n",
      "  Rows: 520\n",
      "  Columns: 28\n",
      "  Total Nulls: 892\n",
      "  Memory: 0.46 MB\n",
      "\n",
      "======================================================================\n",
      "EXPORTING CLEANED DATASETS\n",
      "======================================================================\n",
      "\n",
      "âœ… All cleaned datasets exported to 'cleaned_data/' folder\n",
      "\n",
      "======================================================================\n",
      "DATA WRANGLING DOCUMENTATION (for PowerPoint)\n",
      "======================================================================\n",
      "\n",
      "                       Field Name Records Affected                                                                Action Taken\n",
      "       All Columns (All Datasets)              All Removed leading/trailing whitespace, standardized column names to uppercase\n",
      "        STUDENT ID (All Datasets)  307 + 522 + 511            Trimmed whitespace, validated format consistency across datasets\n",
      "CLASS (Extracted from STUDENT ID)  307 + 522 + 511          Extracted 3-digit CLASS code from STUDENT ID format (XXXX-CCC/III)\n",
      "         PERIOD (Results, Survey)        522 + 511                           Trimmed whitespace, ensured consistent formatting\n",
      "   NATIONALITY columns (Profiles)              307   Created NATIONALITY_STATUS column from SG CITIZEN, SG PR, FOREIGNER flags\n",
      "          Date columns (Profiles)              307          Converted to datetime format, created AGE and COURSE_DURATION_DAYS\n",
      "     COMMENCEMENT DATE (Profiles)                5                        Filled missing dates using mode from same CLASS code\n",
      "       COMPLETION DATE (Profiles)                5                        Filled missing dates using mode from same CLASS code\n",
      "  COURSE_DURATION_DAYS (Profiles)              274         Calculated/recalculated after filling commence and completion dates\n",
      "                    GPA (Results)              522                       Validated range (0-5), checked for nulls and outliers\n",
      "             ATTENDANCE (Results)              522               Validated range (0-100), checked for nulls and invalid values\n",
      "        Survey responses (Survey)              511                   Validated response scales, checked for nulls and outliers\n",
      "      Duplicate records (Results)               33              Removed duplicate STUDENT ID + PERIOD combinations, kept first\n",
      "       Duplicate records (Survey)               32              Removed duplicate STUDENT ID + PERIOD combinations, kept first\n",
      "                GENDER (Profiles)                0                                        Filled missing values with \"Unknown\"\n",
      "\n",
      "âœ… Data wrangling log exported\n",
      "\n",
      "======================================================================\n",
      "QUICK EXPLORATORY DATA ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "1. GENDER Distribution:\n",
      "GENDER\n",
      "F    265\n",
      "M     42\n",
      "Name: count, dtype: int64\n",
      "\n",
      "2. NATIONALITY_STATUS Distribution:\n",
      "NATIONALITY_STATUS\n",
      "SG Citizen    239\n",
      "Foreigner      36\n",
      "SG PR          32\n",
      "Name: count, dtype: int64\n",
      "\n",
      "3. CLASS Distribution:\n",
      "CLASS\n",
      "1101-009     11\n",
      "1101-010     12\n",
      "1101-011     10\n",
      "1101-012     11\n",
      "1102-001      8\n",
      "1102-002      7\n",
      "1102-003      7\n",
      "1102-004      8\n",
      "2101-107     10\n",
      "2101-108A     8\n",
      "2101-109      8\n",
      "2101-110      8\n",
      "2101-111      8\n",
      "2102-063     16\n",
      "2102-064     14\n",
      "2102-065A    12\n",
      "2102-066     16\n",
      "2102-067A    11\n",
      "2102-068A    10\n",
      "2102-069     11\n",
      "2102-070     11\n",
      "5112-008     14\n",
      "5112-009     11\n",
      "5112-010     10\n",
      "5112-011     10\n",
      "5113-005      7\n",
      "5113-006      7\n",
      "5113-007     17\n",
      "5113-008      7\n",
      "5113-009      7\n",
      "Name: count, dtype: int64\n",
      "\n",
      "4. FULL-TIME OR PART-TIME Distribution:\n",
      "FULL-TIME OR PART-TIME\n",
      "Part-Time    237\n",
      "Full-Time     41\n",
      "Part Time     29\n",
      "Name: count, dtype: int64\n",
      "\n",
      "5. GPA Distribution by Period:\n",
      "        count      mean       std  min   25%  50%   75%  max\n",
      "PERIOD                                                      \n",
      "Sem 1   291.0  3.066667  0.580745  1.6  2.70  3.2  3.50  4.0\n",
      "Sem 2   154.0  3.124026  0.596072  1.7  2.70  3.3  3.60  4.0\n",
      "Sem 3    75.0  3.301333  0.626551  1.6  2.85  3.4  3.85  4.0\n",
      "Sem 4     2.0  2.200000  0.141421  2.1  2.15  2.2  2.25  2.3\n",
      "\n",
      "6. Average Survey Scores:\n",
      "PRIOR KNOWLEDGE     3.68\n",
      "COURSE RELEVANCE    3.94\n",
      "TEACHING SUPPORT    3.70\n",
      "COMPANY SUPPORT     3.86\n",
      "FAMILY SUPPORT      3.85\n",
      "dtype: float64\n",
      "\n",
      "7. Self-Study Hours Distribution:\n",
      "count    511.000000\n",
      "mean      13.422701\n",
      "std        4.212190\n",
      "min        5.000000\n",
      "25%       10.000000\n",
      "50%       13.000000\n",
      "75%       17.000000\n",
      "max       23.000000\n",
      "Name: SELF-STUDY HRS, dtype: float64\n",
      "\n",
      "======================================================================\n",
      "âœ… DATA WRANGLING COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "Next Steps:\n",
      "  1. Review cleaned datasets in 'cleaned_data/' folder\n",
      "  2. Use master_dataset.csv for integrated analysis\n",
      "  3. Use individual clean datasets for specific analyses\n",
      "  4. Proceed to visualization phase (Plotly charts)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# DAVI CA2: Educational Dataset - Complete Data Wrangling Notebook\n",
    "# ===================================================================\n",
    "# Authors: [Student Name 1] + [Student Name 2]\n",
    "# Date: January 2026\n",
    "# Purpose: Clean and prepare educational datasets for analysis\n",
    "# ===================================================================\n",
    "\n",
    "# ===================================================================\n",
    "# CELL 1: Import Required Libraries\n",
    "# ===================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For data visualization during cleaning\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"âœ… Libraries imported successfully\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "\n",
    "# ===================================================================\n",
    "# CELL 2: Load All Datasets\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LOADING ALL DATASETS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load datasets\n",
    "try:\n",
    "    df_course_codes = pd.read_csv('CA2 datasets & meta data/Course Codes.csv', encoding='utf-8')\n",
    "    df_meta = pd.read_csv('CA2 datasets & meta data/Meta Data.csv', encoding='utf-8')\n",
    "    df_profiles = pd.read_csv('CA2 datasets & meta data/Student Profiles.csv', encoding='utf-8')\n",
    "    df_results = pd.read_csv('CA2 datasets & meta data/Student Results.csv', encoding='utf-8')\n",
    "    df_survey = pd.read_csv('CA2 datasets & meta data/Student Survey.csv', encoding='utf-8')\n",
    "    \n",
    "    print(\"âœ… All datasets loaded successfully\\n\")\n",
    "    \n",
    "    # Display shapes\n",
    "    datasets = {\n",
    "        'Course Codes': df_course_codes,\n",
    "        'Meta Data': df_meta,\n",
    "        'Student Profiles': df_profiles,\n",
    "        'Student Results': df_results,\n",
    "        'Student Survey': df_survey\n",
    "    }\n",
    "    \n",
    "    for name, df in datasets.items():\n",
    "        print(f\"{name:20s}: {df.shape[0]:4d} rows Ã— {df.shape[1]:2d} columns\")\n",
    "        \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"âŒ Error: {e}\")\n",
    "    print(\"Please ensure all CSV files are in the same directory as this notebook\")\n",
    "\n",
    "# ===================================================================\n",
    "# CELL 3: Initial Data Exploration - Course Codes\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATASET 1: COURSE CODES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df_course_codes.head())\n",
    "\n",
    "print(\"\\nData Info:\")\n",
    "print(df_course_codes.info())\n",
    "\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df_course_codes.isnull().sum())\n",
    "\n",
    "print(\"\\nUnique Courses:\")\n",
    "print(df_course_codes['COURSE NAME'].tolist())\n",
    "\n",
    "# ===================================================================\n",
    "# CELL 4: Initial Data Exploration - Student Profiles\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATASET 2: STUDENT PROFILES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df_profiles.head())\n",
    "\n",
    "print(\"\\nData Info:\")\n",
    "print(df_profiles.info())\n",
    "\n",
    "print(\"\\nMissing Values Summary:\")\n",
    "missing_profiles = df_profiles.isnull().sum()\n",
    "missing_pct = (missing_profiles / len(df_profiles) * 100).round(2)\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_profiles,\n",
    "    'Percentage': missing_pct\n",
    "}).sort_values('Percentage', ascending=False)\n",
    "print(missing_df[missing_df['Missing Count'] > 0])\n",
    "\n",
    "print(\"\\nColumn Names:\")\n",
    "for i, col in enumerate(df_profiles.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")\n",
    "\n",
    "# Sample STUDENT IDs to understand format\n",
    "print(\"\\nSample STUDENT IDs (to understand format):\")\n",
    "print(df_profiles['STUDENT ID'].head(10).tolist())\n",
    "\n",
    "# ===================================================================\n",
    "# CELL 5: Initial Data Exploration - Student Results\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATASET 3: STUDENT RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nFirst 10 rows:\")\n",
    "print(df_results.head(10))\n",
    "\n",
    "print(\"\\nData Info:\")\n",
    "print(df_results.info())\n",
    "\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df_results.isnull().sum())\n",
    "\n",
    "print(\"\\nBasic Statistics:\")\n",
    "print(df_results.describe())\n",
    "\n",
    "print(\"\\nUnique values per column:\")\n",
    "for col in df_results.columns:\n",
    "    print(f\"{col:15s}: {df_results[col].nunique():4d} unique values\")\n",
    "\n",
    "print(\"\\nPERIOD values:\")\n",
    "print(df_results['PERIOD'].value_counts().sort_index())\n",
    "\n",
    "# ===================================================================\n",
    "# CELL 6: Initial Data Exploration - Student Survey\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATASET 4: STUDENT SURVEY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nFirst 10 rows:\")\n",
    "print(df_survey.head(10))\n",
    "\n",
    "print(\"\\nData Info:\")\n",
    "print(df_survey.info())\n",
    "\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df_survey.isnull().sum())\n",
    "\n",
    "print(\"\\nBasic Statistics:\")\n",
    "print(df_survey.describe())\n",
    "\n",
    "print(\"\\nUnique values per column:\")\n",
    "for col in df_survey.columns:\n",
    "    print(f\"{col:20s}: {df_survey[col].nunique():4d} unique values\")\n",
    "\n",
    "print(\"\\nPERIOD values:\")\n",
    "print(df_survey['PERIOD'].value_counts().sort_index())\n",
    "\n",
    "# ===================================================================\n",
    "# CELL 7: Parse STUDENT ID to Extract CLASS Code\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PARSING STUDENT ID - EXTRACTING CLASS CODE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# STUDENT ID Format: XXXX-CCC/III\n",
    "# XXXX = 4 digit number\n",
    "# CCC = 3 digit CLASS code (this is what we need!)\n",
    "# III = 3 digit student index within class\n",
    "\n",
    "def extract_class_from_student_id(student_id):\n",
    "    \"\"\"\n",
    "    Extract the CLASS code from STUDENT ID\n",
    "    Format: XXXX-CCC/III \n",
    "    We need XXXX-CCC (first 4 digits + dash + 3 digit class code)\n",
    "    Example: 1101-009/002 â†’ class code is '1101-009'\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if pd.isna(student_id):\n",
    "            return None\n",
    "        student_id = str(student_id).strip()\n",
    "        \n",
    "        # Split by '/' to remove the student index\n",
    "        if '/' in student_id:\n",
    "            class_code = student_id.split('/')[0]  # Gets '1101-009'\n",
    "            return class_code\n",
    "        else:\n",
    "            return student_id if '-' in student_id else None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Apply to all datasets that have STUDENT ID\n",
    "print(\"\\nExtracting CLASS codes from STUDENT ID...\")\n",
    "\n",
    "# Profiles\n",
    "df_profiles['CLASS'] = df_profiles['STUDENT ID'].apply(extract_class_from_student_id)\n",
    "print(f\"âœ… Profiles: Extracted CLASS for {df_profiles['CLASS'].notna().sum()} students\")\n",
    "\n",
    "# Results  \n",
    "df_results['CLASS'] = df_results['STUDENT ID'].apply(extract_class_from_student_id)\n",
    "print(f\"âœ… Results: Extracted CLASS for {df_results['CLASS'].notna().sum()} records\")\n",
    "\n",
    "# Survey\n",
    "df_survey['CLASS'] = df_survey['STUDENT ID'].apply(extract_class_from_student_id)\n",
    "print(f\"âœ… Survey: Extracted CLASS for {df_survey['CLASS'].notna().sum()} records\")\n",
    "\n",
    "# Show unique classes\n",
    "print(f\"\\nðŸ“Š Unique CLASS codes found:\")\n",
    "all_classes = pd.concat([df_profiles['CLASS'], df_results['CLASS'], df_survey['CLASS']]).unique()\n",
    "all_classes = sorted([c for c in all_classes if pd.notna(c)])\n",
    "print(f\"Total unique classes: {len(all_classes)}\")\n",
    "print(f\"Classes: {all_classes}\")\n",
    "\n",
    "# Show distribution\n",
    "print(f\"\\nCLASS distribution in Profiles:\")\n",
    "print(df_profiles['CLASS'].value_counts().sort_index())\n",
    "\n",
    "# ===================================================================\n",
    "# CELL 8: Cross-Dataset Relationship Analysis\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CROSS-DATASET RELATIONSHIP ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check STUDENT ID consistency\n",
    "unique_profiles = set(df_profiles['STUDENT ID'].unique())\n",
    "unique_results = set(df_results['STUDENT ID'].unique())\n",
    "unique_survey = set(df_survey['STUDENT ID'].unique())\n",
    "\n",
    "print(f\"\\nUnique Student IDs:\")\n",
    "print(f\"  Profiles: {len(unique_profiles)}\")\n",
    "print(f\"  Results:  {len(unique_results)}\")\n",
    "print(f\"  Survey:   {len(unique_survey)}\")\n",
    "\n",
    "print(f\"\\nStudents in Results but NOT in Profiles: {len(unique_results - unique_profiles)}\")\n",
    "print(f\"Students in Survey but NOT in Profiles:  {len(unique_survey - unique_profiles)}\")\n",
    "print(f\"Students in Profiles but NOT in Results: {len(unique_profiles - unique_results)}\")\n",
    "print(f\"Students in Profiles but NOT in Survey:  {len(unique_profiles - unique_survey)}\")\n",
    "\n",
    "# Check PERIOD consistency\n",
    "print(f\"\\nPERIOD Analysis:\")\n",
    "print(f\"  Results PERIOD values: {sorted(df_results['PERIOD'].unique())}\")\n",
    "print(f\"  Survey PERIOD values:  {sorted(df_survey['PERIOD'].unique())}\")\n",
    "\n",
    "# Check for duplicates\n",
    "print(f\"\\nDuplicate Analysis:\")\n",
    "print(f\"  Profiles duplicates (STUDENT ID): {df_profiles['STUDENT ID'].duplicated().sum()}\")\n",
    "print(f\"  Results duplicates (STUDENT ID + PERIOD): {df_results.duplicated(subset=['STUDENT ID', 'PERIOD']).sum()}\")\n",
    "print(f\"  Survey duplicates (STUDENT ID + PERIOD): {df_survey.duplicated(subset=['STUDENT ID', 'PERIOD']).sum()}\")\n",
    "\n",
    "# ===================================================================\n",
    "# CELL 9: Clean Course Codes Dataset\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CLEANING: COURSE CODES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "df_course_codes_clean = df_course_codes.copy()\n",
    "\n",
    "# Check for issues\n",
    "print(\"Before cleaning:\")\n",
    "print(f\"  Shape: {df_course_codes_clean.shape}\")\n",
    "print(f\"  Nulls: {df_course_codes_clean.isnull().sum().sum()}\")\n",
    "\n",
    "# Remove any whitespace from column names\n",
    "df_course_codes_clean.columns = df_course_codes_clean.columns.str.strip()\n",
    "\n",
    "# Remove whitespace from string columns\n",
    "for col in df_course_codes_clean.select_dtypes(include='object').columns:\n",
    "    df_course_codes_clean[col] = df_course_codes_clean[col].str.strip()\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = df_course_codes_clean.duplicated().sum()\n",
    "if duplicates > 0:\n",
    "    print(f\"  âš ï¸  Found {duplicates} duplicate rows - removing...\")\n",
    "    df_course_codes_clean = df_course_codes_clean.drop_duplicates()\n",
    "\n",
    "print(\"\\nAfter cleaning:\")\n",
    "print(f\"  Shape: {df_course_codes_clean.shape}\")\n",
    "print(df_course_codes_clean)\n",
    "\n",
    "# ===================================================================\n",
    "# CELL 10: Clean Student Profiles - Part 1 (Column Cleanup)\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CLEANING: STUDENT PROFILES - PART 1 (Columns)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "df_profiles_clean = df_profiles.copy()\n",
    "\n",
    "print(\"Step 1: Standardize column names\")\n",
    "df_profiles_clean.columns = df_profiles_clean.columns.str.strip().str.upper()\n",
    "print(f\"  âœ… Standardized {len(df_profiles_clean.columns)} column names\")\n",
    "\n",
    "print(\"\\nStep 2: Remove whitespace from all string columns\")\n",
    "for col in df_profiles_clean.select_dtypes(include='object').columns:\n",
    "    if col != 'CLASS':  # Don't strip CLASS since we just created it\n",
    "        df_profiles_clean[col] = df_profiles_clean[col].str.strip()\n",
    "print(\"  âœ… Whitespace removed\")\n",
    "\n",
    "print(\"\\nStep 3: Standardize and fix nationality columns\")\n",
    "\n",
    "# First, standardize the citizenship columns (Y/N instead of Yes/No)\n",
    "print(\"\\nðŸ“Š BEFORE Standardization:\")\n",
    "print(f\"SG CITIZEN unique values: {df_profiles_clean['SG CITIZEN'].unique()}\")\n",
    "print(f\"SG PR unique values: {df_profiles_clean['SG PR'].unique()}\")\n",
    "print(f\"FOREIGNER unique values: {df_profiles_clean['FOREIGNER'].unique()}\")\n",
    "\n",
    "def standardize_yes_no(value):\n",
    "    \"\"\"\n",
    "    Standardize Yes/No/Y/N values to consistent 'Y' or 'N'\n",
    "    \"\"\"\n",
    "    if pd.isna(value):\n",
    "        return 'N'\n",
    "    \n",
    "    value_str = str(value).strip().upper()\n",
    "    \n",
    "    if value_str in ['YES', 'Y', '1', 'TRUE']:\n",
    "        return 'Y'\n",
    "    elif value_str in ['NO', 'N', '0', 'FALSE', '']:\n",
    "        return 'N'\n",
    "    else:\n",
    "        return 'N'\n",
    "\n",
    "# Apply standardization\n",
    "df_profiles_clean['SG CITIZEN'] = df_profiles_clean['SG CITIZEN'].apply(standardize_yes_no)\n",
    "df_profiles_clean['SG PR'] = df_profiles_clean['SG PR'].apply(standardize_yes_no)\n",
    "df_profiles_clean['FOREIGNER'] = df_profiles_clean['FOREIGNER'].apply(standardize_yes_no)\n",
    "\n",
    "print(\"\\nðŸ“Š AFTER Standardization:\")\n",
    "print(f\"SG CITIZEN unique values: {df_profiles_clean['SG CITIZEN'].unique()}\")\n",
    "print(f\"SG PR unique values: {df_profiles_clean['SG PR'].unique()}\")\n",
    "print(f\"FOREIGNER unique values: {df_profiles_clean['FOREIGNER'].unique()}\")\n",
    "\n",
    "# Now create NATIONALITY_STATUS\n",
    "def determine_nationality_simple(row):\n",
    "    if row['SG CITIZEN'] == 'Y':\n",
    "        return 'SG Citizen'\n",
    "    elif row['SG PR'] == 'Y':\n",
    "        return 'SG PR'\n",
    "    elif row['FOREIGNER'] == 'Y':\n",
    "        return 'Foreigner'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "df_profiles_clean['NATIONALITY_STATUS'] = df_profiles_clean.apply(\n",
    "    determine_nationality_simple, axis=1\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Created NATIONALITY_STATUS column\")\n",
    "print(\"\\nðŸ“Š Distribution:\")\n",
    "nationality_counts = df_profiles_clean['NATIONALITY_STATUS'].value_counts()\n",
    "print(nationality_counts)\n",
    "\n",
    "print(\"\\nPercentages:\")\n",
    "for status, count in nationality_counts.items():\n",
    "    pct = (count / len(df_profiles_clean) * 100)\n",
    "    print(f\"  {status}: {count} ({pct:.1f}%)\")\n",
    "\n",
    "unknown_cases = df_profiles_clean[df_profiles_clean['NATIONALITY_STATUS'] == 'Unknown']\n",
    "if len(unknown_cases) > 0:\n",
    "    print(f\"\\nâš ï¸  WARNING: {len(unknown_cases)} students have 'Unknown' nationality\")\n",
    "    print(\"Sample:\")\n",
    "    print(unknown_cases[['STUDENT ID', 'SG CITIZEN', 'SG PR', 'FOREIGNER']].head(10))\n",
    "else:\n",
    "    print(\"\\nâœ… No Unknown nationality cases!\")\n",
    "\n",
    "print(\"\\nðŸ” Data Quality Check:\")\n",
    "df_profiles_clean['citizenship_flags_count'] = (\n",
    "    (df_profiles_clean['SG CITIZEN'] == 'Y').astype(int) +\n",
    "    (df_profiles_clean['SG PR'] == 'Y').astype(int) +\n",
    "    (df_profiles_clean['FOREIGNER'] == 'Y').astype(int)\n",
    ")\n",
    "\n",
    "multiple_flags = df_profiles_clean[df_profiles_clean['citizenship_flags_count'] > 1]\n",
    "if len(multiple_flags) > 0:\n",
    "    print(f\"  âš ï¸  {len(multiple_flags)} students have multiple citizenship flags\")\n",
    "else:\n",
    "    print(\"  âœ… No multiple flags\")\n",
    "\n",
    "no_flags = df_profiles_clean[df_profiles_clean['citizenship_flags_count'] == 0]\n",
    "if len(no_flags) > 0:\n",
    "    print(f\"  âš ï¸  {len(no_flags)} students have NO citizenship flag\")\n",
    "else:\n",
    "    print(\"  âœ… All students have flags\")\n",
    "\n",
    "df_profiles_clean = df_profiles_clean.drop('citizenship_flags_count', axis=1)\n",
    "\n",
    "# ===================================================================\n",
    "# CELL 11: Clean Student Profiles - Part 2 (Date Columns)\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CLEANING: STUDENT PROFILES - PART 2 (Dates)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Handle date columns\n",
    "date_columns = ['DOB', 'DATE ATTAINED HIGHEST QUALIFICATION', \n",
    "                'COMMENCEMENT DATE', 'COMPLETION DATE']\n",
    "\n",
    "print(\"Converting date columns to datetime...\")\n",
    "for col in date_columns:\n",
    "    print(f\"\\nProcessing: {col}\")\n",
    "    # Check current format\n",
    "    print(f\"  Sample values: {df_profiles_clean[col].head(3).tolist()}\")\n",
    "    \n",
    "    # Try to convert to datetime\n",
    "    df_profiles_clean[col] = pd.to_datetime(df_profiles_clean[col], errors='coerce')\n",
    "    \n",
    "    # Report conversion\n",
    "    nulls = df_profiles_clean[col].isnull().sum()\n",
    "    print(f\"  âœ… Converted. Nulls: {nulls} ({nulls/len(df_profiles_clean)*100:.1f}%)\")\n",
    "\n",
    "# Calculate age from DOB\n",
    "from datetime import datetime\n",
    "current_date = pd.Timestamp('2026-01-19')  # Use assignment date\n",
    "\n",
    "# ===================================================================\n",
    "# FIX 1: Convert date columns to datetime format\n",
    "# ===================================================================\n",
    "print(\"\\nðŸ”§ Converting date columns to datetime format...\")\n",
    "\n",
    "df_profiles_clean['DOB'] = pd.to_datetime(df_profiles_clean['DOB'], errors='coerce')\n",
    "df_profiles_clean['DATE ATTAINED HIGHEST QUALIFICATION'] = pd.to_datetime(df_profiles_clean['DATE ATTAINED HIGHEST QUALIFICATION'], errors='coerce')\n",
    "df_profiles_clean['COMMENCEMENT DATE'] = pd.to_datetime(df_profiles_clean['COMMENCEMENT DATE'], errors='coerce')\n",
    "df_profiles_clean['COMPLETION DATE'] = pd.to_datetime(df_profiles_clean['COMPLETION DATE'], errors='coerce')\n",
    "\n",
    "print('âœ… All date columns converted to datetime format')\n",
    "\n",
    "df_profiles_clean['AGE'] = (current_date - df_profiles_clean['DOB']).dt.days / 365.25\n",
    "df_profiles_clean['AGE'] = df_profiles_clean['AGE'].round(1)\n",
    "\n",
    "print(\"\\nAge Statistics:\")\n",
    "print(df_profiles_clean['AGE'].describe())\n",
    "\n",
    "# Calculate course duration (will recalculate after filling dates)\n",
    "df_profiles_clean['COURSE_DURATION_DAYS'] = (\n",
    "    df_profiles_clean['COMPLETION DATE'] - df_profiles_clean['COMMENCEMENT DATE']\n",
    ").dt.days\n",
    "\n",
    "print(\"\\nCourse Duration Statistics (before filling missing dates):\")\n",
    "print(df_profiles_clean['COURSE_DURATION_DAYS'].describe())\n",
    "\n",
    "# ===================================================================\n",
    "# CELL 12: Smart Date Filling Based on CLASS Code\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SMART DATE FILLING - USING CLASS CODE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nðŸ“Š BEFORE Date Filling:\")\n",
    "print(f\"Missing COMMENCEMENT DATE: {df_profiles_clean['COMMENCEMENT DATE'].isnull().sum()} rows\")\n",
    "print(f\"Missing COMPLETION DATE: {df_profiles_clean['COMPLETION DATE'].isnull().sum()} rows\")\n",
    "\n",
    "# Step 1: Create reference table of dates by CLASS\n",
    "print(\"\\nðŸ” Step 1: Analyzing dates by CLASS (not PERIOD)...\")\n",
    "\n",
    "date_reference = df_profiles_clean.groupby('CLASS').agg({\n",
    "    'COMMENCEMENT DATE': lambda x: x.mode()[0] if not x.mode().empty else pd.NaT,\n",
    "    'COMPLETION DATE': lambda x: x.mode()[0] if not x.mode().empty else pd.NaT\n",
    "}).reset_index()\n",
    "\n",
    "date_reference.columns = ['CLASS', 'REFERENCE_COMMENCE', 'REFERENCE_COMPLETE']\n",
    "\n",
    "print(\"\\nDate Reference Table by CLASS:\")\n",
    "print(date_reference)\n",
    "\n",
    "# Identify classes with no date info\n",
    "classes_no_commence = date_reference[date_reference['REFERENCE_COMMENCE'].isnull()]['CLASS'].tolist()\n",
    "classes_no_complete = date_reference[date_reference['REFERENCE_COMPLETE'].isnull()]['CLASS'].tolist()\n",
    "\n",
    "if classes_no_commence:\n",
    "    print(f\"\\nâš ï¸  WARNING: These CLASSes have NO commencement date info: {classes_no_commence}\")\n",
    "if classes_no_complete:\n",
    "    print(f\"âš ï¸  WARNING: These CLASSes have NO completion date info: {classes_no_complete}\")\n",
    "\n",
    "# Step 2: Fill missing dates\n",
    "print(\"\\nðŸ”§ Step 2: Filling missing dates based on CLASS...\")\n",
    "\n",
    "# Merge reference dates\n",
    "df_profiles_clean = df_profiles_clean.merge(\n",
    "    date_reference,\n",
    "    on='CLASS',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Track what we fill\n",
    "rows_filled_commence = 0\n",
    "rows_filled_complete = 0\n",
    "\n",
    "# Fill COMMENCEMENT DATE\n",
    "mask_missing_commence = df_profiles_clean['COMMENCEMENT DATE'].isnull()\n",
    "mask_has_ref_commence = df_profiles_clean['REFERENCE_COMMENCE'].notna()\n",
    "\n",
    "df_profiles_clean.loc[mask_missing_commence & mask_has_ref_commence, 'COMMENCEMENT DATE'] = \\\n",
    "    df_profiles_clean.loc[mask_missing_commence & mask_has_ref_commence, 'REFERENCE_COMMENCE']\n",
    "\n",
    "rows_filled_commence = (mask_missing_commence & mask_has_ref_commence).sum()\n",
    "\n",
    "# Fill COMPLETION DATE\n",
    "mask_missing_complete = df_profiles_clean['COMPLETION DATE'].isnull()\n",
    "mask_has_ref_complete = df_profiles_clean['REFERENCE_COMPLETE'].notna()\n",
    "\n",
    "df_profiles_clean.loc[mask_missing_complete & mask_has_ref_complete, 'COMPLETION DATE'] = \\\n",
    "    df_profiles_clean.loc[mask_missing_complete & mask_has_ref_complete, 'REFERENCE_COMPLETE']\n",
    "\n",
    "rows_filled_complete = (mask_missing_complete & mask_has_ref_complete).sum()\n",
    "\n",
    "print(f\"\\nâœ… Filled {rows_filled_commence} missing COMMENCEMENT DATEs\")\n",
    "print(f\"âœ… Filled {rows_filled_complete} missing COMPLETION DATEs\")\n",
    "\n",
    "# Drop reference columns\n",
    "df_profiles_clean = df_profiles_clean.drop(['REFERENCE_COMMENCE', 'REFERENCE_COMPLETE'], axis=1)\n",
    "\n",
    "# Step 3: Recalculate duration\n",
    "print(\"\\nðŸ”§ Step 3: Recalculating COURSE_DURATION_DAYS...\")\n",
    "\n",
    "df_profiles_clean['COURSE_DURATION_DAYS'] = (\n",
    "    df_profiles_clean['COMPLETION DATE'] - df_profiles_clean['COMMENCEMENT DATE']\n",
    ").dt.days\n",
    "\n",
    "valid_durations = df_profiles_clean['COURSE_DURATION_DAYS'].notna().sum()\n",
    "print(f\"âœ… Calculated duration for {valid_durations} rows\")\n",
    "\n",
    "# Final report\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ“Š AFTER Date Filling:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Missing COMMENCEMENT DATE: {df_profiles_clean['COMMENCEMENT DATE'].isnull().sum()} rows\")\n",
    "print(f\"Missing COMPLETION DATE: {df_profiles_clean['COMPLETION DATE'].isnull().sum()} rows\")\n",
    "print(f\"Missing COURSE_DURATION_DAYS: {df_profiles_clean['COURSE_DURATION_DAYS'].isnull().sum()} rows\")\n",
    "\n",
    "# Show still-missing cases\n",
    "still_missing = df_profiles_clean[\n",
    "    df_profiles_clean['COMMENCEMENT DATE'].isnull() | \n",
    "    df_profiles_clean['COMPLETION DATE'].isnull()\n",
    "][['STUDENT ID', 'CLASS', 'COMMENCEMENT DATE', 'COMPLETION DATE']].copy()\n",
    "\n",
    "if len(still_missing) > 0:\n",
    "    print(f\"\\nâš ï¸  {len(still_missing)} rows still have missing dates:\")\n",
    "    print(\"\\nBreakdown by CLASS:\")\n",
    "    print(still_missing['CLASS'].value_counts())\n",
    "    print(\"\\nThese CLASSes have no date information from any student.\")\n",
    "else:\n",
    "    print(\"\\nðŸŽ‰ All dates successfully filled!\")\n",
    "\n",
    "print(\"\\nðŸ“ˆ Course Duration Statistics:\")\n",
    "print(df_profiles_clean['COURSE_DURATION_DAYS'].describe())\n",
    "\n",
    "# ===================================================================\n",
    "# CELL 13: Clean Student Profiles - Part 3 (Missing Values)\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CLEANING: STUDENT PROFILES - PART 3 (Missing Values)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nMissing Values Summary:\")\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Column': df_profiles_clean.columns,\n",
    "    'Missing_Count': df_profiles_clean.isnull().sum().values,\n",
    "    'Missing_Pct': (df_profiles_clean.isnull().sum().values / len(df_profiles_clean) * 100).round(2)\n",
    "})\n",
    "missing_summary = missing_summary[missing_summary['Missing_Count'] > 0].sort_values('Missing_Pct', ascending=False)\n",
    "print(missing_summary.to_string(index=False))\n",
    "\n",
    "# Handle specific missing values\n",
    "print(\"\\nHandling missing values:\")\n",
    "\n",
    "# GENDER\n",
    "print(f\"\\n  GENDER missing: {df_profiles_clean['GENDER'].isnull().sum()}\")\n",
    "if df_profiles_clean['GENDER'].isnull().sum() > 0:\n",
    "    df_profiles_clean['GENDER'].fillna('Unknown', inplace=True)\n",
    "    print(\"    âœ… Filled with 'Unknown'\")\n",
    "\n",
    "print(\"\\nDecision: Keep other nulls as-is, document in presentation\")\n",
    "\n",
    "# ===================================================================\n",
    "# CELL 14: Clean Student Results\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CLEANING: STUDENT RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "df_results_clean = df_results.copy()\n",
    "\n",
    "print(\"Step 1: Standardize column names\")\n",
    "df_results_clean.columns = df_results_clean.columns.str.strip().str.upper()\n",
    "\n",
    "print(\"\\nStep 2: Check and clean STUDENT ID\")\n",
    "df_results_clean['STUDENT ID'] = df_results_clean['STUDENT ID'].str.strip()\n",
    "\n",
    "print(\"\\nStep 3: Clean and standardize PERIOD column\")\n",
    "\n",
    "def standardize_period(period_str):\n",
    "    \"\"\"Standardize PERIOD: 'Semester' â†’ 'Sem'\"\"\"\n",
    "    if pd.isna(period_str):\n",
    "        return period_str\n",
    "    period_str = str(period_str).strip()\n",
    "    period_str = period_str.replace('Semester', 'Sem')\n",
    "    period_str = period_str.replace('semester', 'Sem')\n",
    "    period_str = period_str.replace('SEMESTER', 'Sem')\n",
    "    period_str = ' '.join(period_str.split())\n",
    "    return period_str\n",
    "\n",
    "print(f\"  BEFORE: {df_results_clean['PERIOD'].unique()}\")\n",
    "df_results_clean['PERIOD'] = df_results_clean['PERIOD'].str.strip()\n",
    "\n",
    "# ===================================================================\n",
    "# FIX 3: Standardize PERIOD values\n",
    "# ===================================================================\n",
    "print(\"\\nðŸ”§ Standardizing PERIOD values in Results...\")\n",
    "before_period = df_results_clean[\"PERIOD\"].value_counts().sort_index().to_dict()\n",
    "print(f\"Before: {before_period}\")\n",
    "\n",
    "df_results_clean[\"PERIOD\"] = df_results_clean[\"PERIOD\"].str.replace(\"Sem1\", \"Sem 1\", regex=False)\n",
    "df_results_clean[\"PERIOD\"] = df_results_clean[\"PERIOD\"].str.replace(\"Sem2\", \"Sem 2\", regex=False)\n",
    "df_results_clean[\"PERIOD\"] = df_results_clean[\"PERIOD\"].str.replace(\"Sem3\", \"Sem 3\", regex=False)\n",
    "df_results_clean[\"PERIOD\"] = df_results_clean[\"PERIOD\"].str.replace(\"Sem4\", \"Sem 4\", regex=False)\n",
    "df_results_clean[\"PERIOD\"] = df_results_clean[\"PERIOD\"].str.strip()\n",
    "\n",
    "after_period = df_results_clean[\"PERIOD\"].value_counts().sort_index().to_dict()\n",
    "print(f\"After: {after_period}\")\n",
    "print(\"âœ… PERIOD values standardized in Results\")\n",
    "\n",
    "df_results_clean['PERIOD'] = df_results_clean['PERIOD'].apply(standardize_period)\n",
    "print(f\"  AFTER: {df_results_clean['PERIOD'].unique()}\")\n",
    "print(f\"  âœ… PERIOD standardized\")\n",
    "\n",
    "print(\"\\nStep 4: Validate GPA values\")\n",
    "print(f\"  GPA range: {df_results_clean['GPA'].min():.2f} to {df_results_clean['GPA'].max():.2f}\")\n",
    "\n",
    "invalid_gpa = df_results_clean[(df_results_clean['GPA'] < 0) | (df_results_clean['GPA'] > 5)]\n",
    "if len(invalid_gpa) > 0:\n",
    "    print(f\"  âš ï¸  Found {len(invalid_gpa)} invalid GPA values:\")\n",
    "    print(invalid_gpa)\n",
    "else:\n",
    "    print(\"  âœ… All GPA values are valid\")\n",
    "\n",
    "null_gpa = df_results_clean['GPA'].isnull().sum()\n",
    "print(f\"  Null GPAs: {null_gpa}\")\n",
    "\n",
    "print(\"\\nStep 5: Validate ATTENDANCE values\")\n",
    "print(f\"  ATTENDANCE range: {df_results_clean['ATTENDANCE'].min()} to {df_results_clean['ATTENDANCE'].max()}\")\n",
    "print(f\"  Null ATTENDANCE: {df_results_clean['ATTENDANCE'].isnull().sum()}\")\n",
    "\n",
    "invalid_attendance = df_results_clean[(df_results_clean['ATTENDANCE'] < 0) | (df_results_clean['ATTENDANCE'] > 100)]\n",
    "if len(invalid_attendance) > 0:\n",
    "    print(f\"  âš ï¸  Found {len(invalid_attendance)} invalid ATTENDANCE values\")\n",
    "    print(invalid_attendance)\n",
    "else:\n",
    "    print(\"  âœ… All ATTENDANCE values are valid\")\n",
    "\n",
    "print(\"\\nðŸ” Re-checking duplicates after PERIOD standardization...\")\n",
    "duplicates_after = df_results_clean.duplicated(subset=['STUDENT ID', 'PERIOD']).sum()\n",
    "if duplicates_after > 0:\n",
    "    print(f\"  âš ï¸  Found {duplicates_after} new duplicates after standardization\")\n",
    "    df_results_clean = df_results_clean.drop_duplicates(subset=['STUDENT ID', 'PERIOD'], keep='first')\n",
    "    print(f\"  âœ… Removed duplicates\")\n",
    "\n",
    "print(\"\\nStep 6: Check for duplicate records\")\n",
    "duplicates = df_results_clean.duplicated(subset=['STUDENT ID', 'PERIOD']).sum()\n",
    "print(f\"  Duplicates (STUDENT ID + PERIOD): {duplicates}\")\n",
    "if duplicates > 0:\n",
    "    print(\"  âš ï¸  Removing duplicates...\")\n",
    "    df_results_clean = df_results_clean.drop_duplicates(subset=['STUDENT ID', 'PERIOD'], keep='first')\n",
    "    print(f\"  âœ… Removed {duplicates} duplicate records\")\n",
    "\n",
    "print(f\"\\nFinal shape: {df_results_clean.shape}\")\n",
    "\n",
    "# ===================================================================\n",
    "# CELL 15: Clean Student Survey\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CLEANING: STUDENT SURVEY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "df_survey_clean = df_survey.copy()\n",
    "\n",
    "print(\"Step 1: Standardize column names\")\n",
    "df_survey_clean.columns = df_survey_clean.columns.str.strip().str.upper()\n",
    "\n",
    "print(\"\\nStep 2: Clean STUDENT ID and PERIOD\")\n",
    "\n",
    "def standardize_period(period_str):\n",
    "    \"\"\"Standardize PERIOD: 'Semester' â†’ 'Sem'\"\"\"\n",
    "    if pd.isna(period_str):\n",
    "        return period_str\n",
    "    period_str = str(period_str).strip()\n",
    "    period_str = period_str.replace('Semester', 'Sem')\n",
    "    period_str = period_str.replace('semester', 'Sem')\n",
    "    period_str = period_str.replace('SEMESTER', 'Sem')\n",
    "    period_str = ' '.join(period_str.split())\n",
    "    return period_str\n",
    "\n",
    "df_survey_clean['STUDENT ID'] = df_survey_clean['STUDENT ID'].str.strip()\n",
    "\n",
    "print(f\"  BEFORE: {df_survey_clean['PERIOD'].unique()}\")\n",
    "df_survey_clean['PERIOD'] = df_survey_clean['PERIOD'].str.strip()\n",
    "\n",
    "# ===================================================================\n",
    "# FIX 4: Standardize PERIOD values\n",
    "# ===================================================================\n",
    "print(\"\\nðŸ”§ Standardizing PERIOD values in Survey...\")\n",
    "before_period = df_survey_clean[\"PERIOD\"].value_counts().sort_index().to_dict()\n",
    "print(f\"Before: {before_period}\")\n",
    "\n",
    "df_survey_clean[\"PERIOD\"] = df_survey_clean[\"PERIOD\"].str.replace(\"Sem1\", \"Sem 1\", regex=False)\n",
    "df_survey_clean[\"PERIOD\"] = df_survey_clean[\"PERIOD\"].str.replace(\"Sem2\", \"Sem 2\", regex=False)\n",
    "df_survey_clean[\"PERIOD\"] = df_survey_clean[\"PERIOD\"].str.replace(\"Sem3\", \"Sem 3\", regex=False)\n",
    "df_survey_clean[\"PERIOD\"] = df_survey_clean[\"PERIOD\"].str.replace(\"Sem4\", \"Sem 4\", regex=False)\n",
    "df_survey_clean[\"PERIOD\"] = df_survey_clean[\"PERIOD\"].str.strip()\n",
    "\n",
    "after_period = df_survey_clean[\"PERIOD\"].value_counts().sort_index().to_dict()\n",
    "print(f\"After: {after_period}\")\n",
    "print(\"âœ… PERIOD values standardized in Survey\")\n",
    "\n",
    "df_survey_clean['PERIOD'] = df_survey_clean['PERIOD'].apply(standardize_period)\n",
    "print(f\"  AFTER: {df_survey_clean['PERIOD'].unique()}\")\n",
    "print(f\"  âœ… PERIOD standardized\")\n",
    "\n",
    "print(\"\\nStep 3: Validate survey response columns\")\n",
    "survey_cols = ['PRIOR KNOWLEDGE', 'COURSE RELEVANCE', 'TEACHING SUPPORT', \n",
    "               'COMPANY SUPPORT', 'FAMILY SUPPORT', 'SELF-STUDY HRS']\n",
    "\n",
    "for col in survey_cols:\n",
    "    print(f\"\\n  {col}:\")\n",
    "    print(f\"    Range: {df_survey_clean[col].min()} to {df_survey_clean[col].max()}\")\n",
    "    print(f\"    Nulls: {df_survey_clean[col].isnull().sum()}\")\n",
    "    print(f\"    Unique: {df_survey_clean[col].nunique()} values\")\n",
    "\n",
    "print(\"\\nðŸ” Re-checking duplicates after PERIOD standardization...\")\n",
    "duplicates_after = df_survey_clean.duplicated(subset=['STUDENT ID', 'PERIOD']).sum()\n",
    "if duplicates_after > 0:\n",
    "    print(f\"  âš ï¸  Found {duplicates_after} new duplicates after standardization\")\n",
    "    df_survey_clean = df_survey_clean.drop_duplicates(subset=['STUDENT ID', 'PERIOD'], keep='first')\n",
    "    print(f\"  âœ… Removed duplicates\")\n",
    "\n",
    "print(\"\\nStep 4: Check for duplicate records\")\n",
    "duplicates = df_survey_clean.duplicated(subset=['STUDENT ID', 'PERIOD']).sum()\n",
    "print(f\"  Duplicates (STUDENT ID + PERIOD): {duplicates}\")\n",
    "if duplicates > 0:\n",
    "    print(\"  âš ï¸  Removing duplicates...\")\n",
    "    df_survey_clean = df_survey_clean.drop_duplicates(subset=['STUDENT ID', 'PERIOD'], keep='first')\n",
    "    print(f\"  âœ… Removed {duplicates} duplicate records\")\n",
    "\n",
    "print(f\"\\nFinal shape: {df_survey_clean.shape}\")\n",
    "\n",
    "# ===================================================================\n",
    "# CELL 16: Cross-Dataset Validation\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CROSS-DATASET VALIDATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "students_profiles = set(df_profiles_clean['STUDENT ID'].unique())\n",
    "students_results = set(df_results_clean['STUDENT ID'].unique())\n",
    "students_survey = set(df_survey_clean['STUDENT ID'].unique())\n",
    "\n",
    "print(\"\\nStudent ID Coverage:\")\n",
    "print(f\"  Profiles: {len(students_profiles)} students\")\n",
    "print(f\"  Results:  {len(students_results)} students\")\n",
    "print(f\"  Survey:   {len(students_survey)} students\")\n",
    "\n",
    "orphan_results = students_results - students_profiles\n",
    "if len(orphan_results) > 0:\n",
    "    print(f\"\\n  âš ï¸  {len(orphan_results)} students in Results without Profile:\")\n",
    "    print(f\"    {list(orphan_results)[:10]}...\")\n",
    "\n",
    "orphan_survey = students_survey - students_profiles\n",
    "if len(orphan_survey) > 0:\n",
    "    print(f\"\\n  âš ï¸  {len(orphan_survey)} students in Survey without Profile:\")\n",
    "    print(f\"    {list(orphan_survey)[:10]}...\")\n",
    "\n",
    "print(\"\\nPERIOD Consistency:\")\n",
    "periods_results = set(df_results_clean['PERIOD'].unique())\n",
    "periods_survey = set(df_survey_clean['PERIOD'].unique())\n",
    "print(f\"  Results periods: {sorted(periods_results)}\")\n",
    "print(f\"  Survey periods:  {sorted(periods_survey)}\")\n",
    "\n",
    "# ===================================================================\n",
    "# CELL 17: Create Master Dataset\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CREATING MASTER DATASET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nMerging strategy:\")\n",
    "print(\"  1. Merge Results with Survey on STUDENT ID + PERIOD\")\n",
    "print(\"  2. Merge with Profiles on STUDENT ID\")\n",
    "\n",
    "# Merge Results + Survey\n",
    "df_results_survey = pd.merge(\n",
    "    df_results_clean,\n",
    "    df_survey_clean,\n",
    "    on=['STUDENT ID', 'PERIOD', 'CLASS'],\n",
    "    how='outer',\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "print(f\"\\nResults + Survey merge:\")\n",
    "print(f\"  Both: {(df_results_survey['_merge'] == 'both').sum()}\")\n",
    "print(f\"  Only Results: {(df_results_survey['_merge'] == 'left_only').sum()}\")\n",
    "print(f\"  Only Survey: {(df_results_survey['_merge'] == 'right_only').sum()}\")\n",
    "\n",
    "df_results_survey = df_results_survey.drop('_merge', axis=1)\n",
    "\n",
    "# Merge with Profiles\n",
    "df_master = pd.merge(\n",
    "    df_profiles_clean,\n",
    "    df_results_survey,\n",
    "    on=['STUDENT ID', 'CLASS'],\n",
    "    how='left',\n",
    "    suffixes=('_profile', '_course')\n",
    ")\n",
    "\n",
    "print(f\"\\nMaster dataset created:\")\n",
    "print(f\"  Shape: {df_master.shape}\")\n",
    "print(f\"  Students: {df_master['STUDENT ID'].nunique()}\")\n",
    "\n",
    "print(\"\\nMaster dataset columns:\")\n",
    "for i, col in enumerate(df_master.columns, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "# ===================================================================\n",
    "# CELL 18: Final Data Quality Report\n",
    "# ===================================================================\n",
    "\n",
    "# --- NEW STEP: Remove Duplicates from Master Dataset ---\n",
    "print(\"Processing Master Dataset Deduplication...\")\n",
    "rows_before = df_master.shape[0]\n",
    "\n",
    "# drop_duplicates() removes rows where all columns are identical\n",
    "df_master = df_master.drop_duplicates() \n",
    "\n",
    "rows_removed = rows_before - df_master.shape[0]\n",
    "print(f\"Done. Removed {rows_removed:,} duplicate rows.\")\n",
    "\n",
    "# --- GENERATE REPORT ---\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL DATA QUALITY REPORT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nðŸ“Š CLEANED DATASETS SUMMARY:\\n\")\n",
    "\n",
    "# ===================================================================\n",
    "# FIX 5: Remove duplicates from Master Dataset\n",
    "# ===================================================================\n",
    "print(\"\\nðŸ”§ Removing duplicates from Master Dataset...\")\n",
    "before_dedup = len(df_master)\n",
    "dup_count = df_master.duplicated(subset=[\"STUDENT ID\", \"PERIOD\"]).sum()\n",
    "print(f\"Duplicates found: {dup_count}\")\n",
    "\n",
    "if dup_count > 0:\n",
    "    dup_records = df_master[df_master.duplicated(subset=[\"STUDENT ID\", \"PERIOD\"], keep=False)]\n",
    "    print(\"Showing duplicate records:\")\n",
    "    print(dup_records[[\"STUDENT ID\", \"PERIOD\", \"GPA\", \"ATTENDANCE\"]].sort_values([\"STUDENT ID\", \"PERIOD\"]).head(10))\n",
    "    \n",
    "    # Remove duplicates\n",
    "    df_master = df_master.drop_duplicates(subset=[\"STUDENT ID\", \"PERIOD\"], keep=\"first\")\n",
    "    after_dedup = len(df_master)\n",
    "    removed = before_dedup - after_dedup\n",
    "    print(f\"âœ… Removed {removed} duplicate rows\")\n",
    "    print(f\"New shape: {df_master.shape}\")\n",
    "else:\n",
    "    print(\"âœ… No duplicates found\")\n",
    "\n",
    "summaries = {\n",
    "    'Course Codes': df_course_codes_clean,\n",
    "    'Student Profiles': df_profiles_clean,\n",
    "    'Student Results': df_results_clean,\n",
    "    'Student Survey': df_survey_clean,\n",
    "    'Master Dataset': df_master  # This now contains the deduplicated data\n",
    "}\n",
    "\n",
    "for name, df in summaries.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Rows: {df.shape[0]:,}\")\n",
    "    print(f\"  Columns: {df.shape[1]}\")\n",
    "    print(f\"  Total Nulls: {df.isnull().sum().sum():,}\")\n",
    "    print(f\"  Memory: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "# ===================================================================\n",
    "# CELL 19: Export Cleaned Datasets\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXPORTING CLEANED DATASETS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create directory\n",
    "import os\n",
    "os.makedirs('cleaned_data', exist_ok=True)\n",
    "\n",
    "# Export\n",
    "df_course_codes_clean.to_csv('cleaned_data/course_codes_clean.csv', index=False)\n",
    "df_profiles_clean.to_csv('cleaned_data/student_profiles_clean.csv', index=False)\n",
    "df_results_clean.to_csv('cleaned_data/student_results_clean.csv', index=False)\n",
    "df_survey_clean.to_csv('cleaned_data/student_survey_clean.csv', index=False)\n",
    "df_master.to_csv('cleaned_data/master_dataset.csv', index=False)\n",
    "\n",
    "print(\"\\nâœ… All cleaned datasets exported to 'cleaned_data/' folder\")\n",
    "\n",
    "# ===================================================================\n",
    "# CELL 20: Create Data Wrangling Documentation\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATA WRANGLING DOCUMENTATION (for PowerPoint)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "wrangling_log = pd.DataFrame({\n",
    "    'Field Name': [\n",
    "        'All Columns (All Datasets)',\n",
    "        'STUDENT ID (All Datasets)',\n",
    "        'CLASS (Extracted from STUDENT ID)',\n",
    "        'PERIOD (Results, Survey)',\n",
    "        'NATIONALITY columns (Profiles)',\n",
    "        'Date columns (Profiles)',\n",
    "        'COMMENCEMENT DATE (Profiles)',\n",
    "        'COMPLETION DATE (Profiles)',\n",
    "        'COURSE_DURATION_DAYS (Profiles)',\n",
    "        'GPA (Results)',\n",
    "        'ATTENDANCE (Results)',\n",
    "        'Survey responses (Survey)',\n",
    "        'Duplicate records (Results)',\n",
    "        'Duplicate records (Survey)',\n",
    "        'GENDER (Profiles)',\n",
    "    ],\n",
    "    'Records Affected': [\n",
    "        'All',\n",
    "        f'{len(df_profiles_clean)} + {len(df_results_clean)} + {len(df_survey_clean)}',\n",
    "        f'{len(df_profiles_clean)} + {len(df_results_clean)} + {len(df_survey_clean)}',\n",
    "        f'{len(df_results_clean)} + {len(df_survey_clean)}',\n",
    "        f'{len(df_profiles_clean)}',\n",
    "        f'{len(df_profiles_clean)}',\n",
    "        f'{rows_filled_commence}',\n",
    "        f'{rows_filled_complete}',\n",
    "        f'{valid_durations}',\n",
    "        f'{len(df_results_clean)}',\n",
    "        f'{len(df_results_clean)}',\n",
    "        f'{len(df_survey_clean)}',\n",
    "        f'{df_results.duplicated(subset=[\"STUDENT ID\", \"PERIOD\"]).sum()}',\n",
    "        f'{df_survey.duplicated(subset=[\"STUDENT ID\", \"PERIOD\"]).sum()}',\n",
    "        f'{df_profiles[\"GENDER\"].isnull().sum()}',\n",
    "    ],\n",
    "    'Action Taken': [\n",
    "        'Removed leading/trailing whitespace, standardized column names to uppercase',\n",
    "        'Trimmed whitespace, validated format consistency across datasets',\n",
    "        'Extracted 3-digit CLASS code from STUDENT ID format (XXXX-CCC/III)',\n",
    "        'Trimmed whitespace, ensured consistent formatting',\n",
    "        'Created NATIONALITY_STATUS column from SG CITIZEN, SG PR, FOREIGNER flags',\n",
    "        'Converted to datetime format, created AGE and COURSE_DURATION_DAYS',\n",
    "        'Filled missing dates using mode from same CLASS code',\n",
    "        'Filled missing dates using mode from same CLASS code',\n",
    "        'Calculated/recalculated after filling commence and completion dates',\n",
    "        'Validated range (0-5), checked for nulls and outliers',\n",
    "        'Validated range (0-100), checked for nulls and invalid values',\n",
    "        'Validated response scales, checked for nulls and outliers',\n",
    "        'Removed duplicate STUDENT ID + PERIOD combinations, kept first',\n",
    "        'Removed duplicate STUDENT ID + PERIOD combinations, kept first',\n",
    "        'Filled missing values with \"Unknown\"',\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + wrangling_log.to_string(index=False))\n",
    "\n",
    "wrangling_log.to_csv('cleaned_data/data_wrangling_log.csv', index=False)\n",
    "print(\"\\nâœ… Data wrangling log exported\")\n",
    "\n",
    "# ===================================================================\n",
    "# CELL 21: Quick EDA\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"QUICK EXPLORATORY DATA ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n1. GENDER Distribution:\")\n",
    "print(df_profiles_clean['GENDER'].value_counts())\n",
    "\n",
    "print(\"\\n2. NATIONALITY_STATUS Distribution:\")\n",
    "print(df_profiles_clean['NATIONALITY_STATUS'].value_counts())\n",
    "\n",
    "print(\"\\n3. CLASS Distribution:\")\n",
    "print(df_profiles_clean['CLASS'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\n4. FULL-TIME OR PART-TIME Distribution:\")\n",
    "print(df_profiles_clean['FULL-TIME OR PART-TIME'].value_counts())\n",
    "\n",
    "print(\"\\n5. GPA Distribution by Period:\")\n",
    "print(df_results_clean.groupby('PERIOD')['GPA'].describe())\n",
    "\n",
    "print(\"\\n6. Average Survey Scores:\")\n",
    "survey_cols = ['PRIOR KNOWLEDGE', 'COURSE RELEVANCE', 'TEACHING SUPPORT', \n",
    "               'COMPANY SUPPORT', 'FAMILY SUPPORT']\n",
    "print(df_survey_clean[survey_cols].mean().round(2))\n",
    "\n",
    "print(\"\\n7. Self-Study Hours Distribution:\")\n",
    "print(df_survey_clean['SELF-STUDY HRS'].describe())\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… DATA WRANGLING COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"  1. Review cleaned datasets in 'cleaned_data/' folder\")\n",
    "print(\"  2. Use master_dataset.csv for integrated analysis\")\n",
    "print(\"  3. Use individual clean datasets for specific analyses\")\n",
    "print(\"  4. Proceed to visualization phase (Plotly charts)\")\n",
    "print(\"=\"*70)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
